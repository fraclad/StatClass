---
title: "Lab 12"
author: "Rahmat Ashari"
date: " `r format(Sys.time(), format = '%b %d, %Y')` "
output: 
  html_document:
    toc: yes
    toc_float: yes
---

# Task 1
```{r}

getwd()

```

# Task 2

### $H_0: \mu = 22$
```{r}

set.seed(55)
x1=rnorm(30,mean=25,sd=5)

t.test(x1, mu = 22)

```
22 is not within CI and p value is less than alpha (=0.05). Hence, reject NULL hypothesis. 

### $H_0: \mu = 23$
```{r}

set.seed(55)
x1=rnorm(30,mean=25,sd=5)

t.test(x1, mu = 23)

```
23 is not within CI and p value is less than alpha (=0.05). Hence, reject NULL hypothesis. 

### $H_0: \mu = 24$
```{r}

set.seed(55)
x1=rnorm(30,mean=25,sd=5)

t.test(x1, mu = 24)

```
24 **is** within CI and p value is greater than alpha(=0.05). Hence, the null value is plausible. 

### $H_0: \mu = 25$
```{r}

set.seed(55)
x1=rnorm(30,mean=25,sd=5)

t.test(x1, mu = 25)

```

25 **is** within CI and p value is greater than alpha(=0.05). Hence, the null value is plausible. 

### $H_0: \mu = 26$
```{r}

set.seed(55)
x1=rnorm(30,mean=25,sd=5)

t.test(x1, mu = 26)

```

26 **is** within CI and p value is greater than alpha(=0.05). Hence, the null value is plausible. 

### Boxplot
```{r}

boxplot(x1, main="Sample x1")
ci=t.test(x1,mu=23)$conf.int
abline(h=c(ci,mean(x1)),col=c("Red","Red","Green"))

```

### $t_{calc}$ for $H_0: \mu = 24$
```{r}

tcalc=(mean(x1)-24)/(sd(x1)/sqrt(30))
tcalc

```


### `mypvalue()` to visualize RAR
```{r}

mypvalue=function(t0,xmax=4,n=20, alpha=0.05){
#calculate alpha/2
va=round(pt(-t0,df=n-1),4)
pv=2*va

# plot the t dist
curve(dt(x,df=n-1),xlim=c(-xmax,xmax),ylab="T Density",xlab=expression(t),
main=substitute(paste("P-value=", pv, " alpha=", alpha)))


# set up points on the polygon to the right
xcurve=seq(t0,xmax,length=1000)
ycurve=dt(xcurve,df=n-1)

# set up points to the left
xlcurve=seq(-t0,-xmax,length=1000)
ylcurve=dt(xcurve,df=n-1)

# Shade in the polygon defined by the line segments
polygon(c(t0,xcurve,xmax),c(0,ycurve,0),col="green")
polygon(c(-t0,xlcurve,-xmax),c(0,ylcurve,0),col="green")

# make quantiles
q=qt(1-alpha/2,n-1)
abline( v=c(q,-q),lwd=2) # plot the cut off t value 
axis(3,c(q,-q),c(expression(abs(t[alpha/2])),expression(-abs(t[alpha/2]))))


# Annotation
text(0.5*(t0+xmax),max(ycurve),substitute(paste(area, "=",va)))
text(-0.5*(t0+xmax),max(ycurve),expression(area))

return(list(q=q,pvalue=pv))
}

mypvalue(tcalc,n=30,alpha=0.05)

```

Rejection region is t>2.04523 and t<2.04523. 

Critical p value is alpha, which in this case is 0.05.

tcalc touches rejection region. 

### Bootstrap
```{r}

bootpval<-function(x,conf.level=0.95,iter=3000,mu0=0, test="two"){
n=length(x)
y=x-mean(x)+mu0  # transform the data so that it is centered at the NULL
rs.mat<-c()    #rs.mat will become a resample matrix -- now it is an empty vector
xrs.mat<-c()
for(i in 1:iter){ # for loop - the loop will go around iter times
rs.mat<-cbind(rs.mat,sample(y,n,replace=TRUE)) #sampling from y cbind -- column bind -- binds the vectors together by columns
xrs.mat<-cbind(xrs.mat,sample(x,n,replace=TRUE)) #sampling from x cbind -- column bind -- binds the vectors together by columns

}

tstat<-function(z){ # The value of t when the NULL is assumed true (xbar-muo)/z/sqrt(n)
sqrt(n)*(mean(z)-mu0)/sd(z)
}

tcalc=tstat(x) # t for the data collected
ytstat=apply(rs.mat,2,tstat) # tstat of resampled y's, ytstat is a vector and will have iter values in it
xstat=apply(xrs.mat,2,mean)  # mean of resampled x's
alpha=1-conf.level # calculating alpha
ci=quantile(xstat,c(alpha/2,1-alpha/2))# Nice way to form a confidence interval
pvalue=ifelse(test=="two",length(ytstat[ytstat>abs(tcalc) | ytstat < -abs(tcalc)])/iter,
ifelse(test=="upper",length(ytstat[ytstat>tcalc])/iter,
length(ytstat[ytstat<xstat])/iter))

h=hist(ytstat,plot=FALSE)
mid=h$mid
if(test=="two"){
ncoll=length(mid[mid<= -abs(tcalc)])
ncolr=length(mid[mid>=  abs(tcalc)])
col=c(rep("Green",ncoll),rep("Gray",length(mid)-ncoll-ncolr),rep("Green",ncolr))
}
if(test=="upper"){
ncolr=length(mid[mid>=  abs(tcalc)])
col=c(rep("Gray",length(mid)-ncolr),rep("Green",ncolr))
}

if(test=="lower"){
ncoll=length(mid[mid<=  -abs(tcalc)])
col=c(rep("Green",ncoll),rep("Gray",length(mid)-ncoll))
}
hist(ytstat,col=col,freq=FALSE,las=1,main="",xlab=expression(T[stat]))
#segments(ci[1],0,ci[2],0,lwd=2)
pround=round(pvalue,4)
title(substitute(paste(P[value],"=",pround)))
invisible(list(pvalue=pvalue,tcalc=tcalc,n=n,x=x,test=test,ci=ci))
}

```

### Bootstrap $H_0: \mu = 22$
```{r}

bootpval(x=x1,conf.level=0.95,iter=3000,mu0=22, test = "two")

```

### Bootstrap $H_0: \mu = 23$
```{r}

bootpval(x=x1,conf.level=0.95,iter=3000,mu0=23, test = "two")

```

### Bootstrap $H_0: \mu = 24$
```{r}

bootpval(x=x1,conf.level=0.95,iter=3000,mu0=24, test = "two")

```

### Bootstrap $H_0: \mu = 25$
```{r}

bootpval(x=x1,conf.level=0.95,iter=3000,mu0=25, test = "two")

```

### Bootstrap $H_0: \mu = 26$
```{r}

bootpval(x=x1,conf.level=0.95,iter=3000,mu0=26, test = "two")

```

Results are arguably close for each case of hypothesis. the t stat is shrinking about 0 as the value is closer to the population mean. 

# Task 3
```{r}

set.seed(30)
x=rnorm(15,mean=10,sd=7)   
set.seed(40)
y=rnorm(20,mean=12,sd=4)

var.test(x,y)

```

the p-value is less than alpha (=0.05) and the value of one is not within the 95% CI. Hence, the variances of the two populations are different. This implies that, whenever we use `t.test()`, the argument `var.equal` must be set to `False`. 

### $H_0: \mu_y - \mu_x = 0$

```{r}

t.test(y,x, mu = 0, var.equal = F)

```

p-value is slightly above alpha (=0.05) and 0 is within the 95% CI. Therefore, it is possible that the difference between the mean of y and x is zero. 

### $H_0: \mu_y - \mu_x = 2$

```{r}

t.test(y,x, mu = 2, var.equal = F)

```

Similarly, p-value is slightly above alpha (=0.05) and 2 is within the 95% CI. Therefore, it is possible that the difference between the mean of y and x is 2. 

From the the two t-stat test, we can infer that the difference of the mean between y and x is at least 0. 

# Task 4 
```{r}

set.seed(30)
x=rnorm(15,mean=10,sd=4)   
set.seed(40)
y=rnorm(20,mean=12,sd=4)

var.test(x,y)

```

The value of 1 **is** within the 95% CI and the p-value is greater than alpha. Hence, it is plausible that the variances to be the same. Consequently, we assign `TRUE` to the argument `var.equal=` in `t.test()`. 

### $H_0: \mu_y - \mu_x = 0$
```{r}

t.test(y,x,mu=0,var.equal = T)

```
The null value is not within 95% Ci and the p value is less than alpha: reject Null hypothesis. 


### $H_0: \mu_y - \mu_x = 2$
```{r}

t.test(y,x,mu=2, var.equal = T)

```
Similarly, p-value is slightly above alpha (=0.05) and 2 is within the 95% CI. Therefore, it is possible that the difference between the mean of y and x is 2. 

# Task 5
```{r}

boot2pval<-function(x1,x2,conf.level=0.95,iter=3000,mudiff=0, test="two"){
n1=length(x1)
n2=length(x2)
y1=x1-mean(x1)+mean(c(x1,x2))  # transform the data so that it is centered at the NULL
y2=x2-mean(x2)+mean(c(x1,x2))
y1rs.mat<-c()    #rs.mat will be come a resample matrix -- now it is an empty vector
x1rs.mat<-c()
y2rs.mat<-c()
x2rs.mat<-c()
for(i in 1:iter){ # for loop - the loop will go around iter times
y1rs.mat<-cbind(y1rs.mat,sample(y1,n1,replace=TRUE)) #sampling from y cbind -- column bind -- binds the vectors together by columns
y2rs.mat<-cbind(y2rs.mat,sample(y2,n2,replace=TRUE))

}
x1rs.mat<-y1rs.mat+mean(x1)-mean(c(x1,x2))
x2rs.mat<-y2rs.mat+mean(x2)-mean(c(x1,x2))

xbar1=mean(x1)
xbar2=mean(x2)
sx1sq=var(x1)
sx2sq=var(x2)

tcalc=(xbar1-xbar2-mudiff)/sqrt(sx1sq/n1+sx2sq/n2)

sy1sq=apply(y1rs.mat,2,var)
sy2sq=apply(y2rs.mat,2,var) 
y1bar=apply(y1rs.mat,2,mean)
y2bar=apply(y2rs.mat,2,mean)

tstat=(y1bar-y2bar-mudiff)/sqrt(sy1sq/n1+sy2sq/n2)


alpha=1-conf.level # calculating alpha
#ci=quantile(xstat,c(alpha/2,1-alpha/2))# Nice way to form a confidence interval
pvalue=ifelse(test=="two",length(tstat[tstat>abs(tcalc) | tstat < -abs(tcalc)])/iter,
ifelse(test=="upper",length(tstat[tstat>tcalc])/iter,
length(ytstat[tstat<tcalc])/iter))

h=hist(tstat,plot=FALSE)
mid=h$mid
if(test=="two"){
ncoll=length(mid[mid<= -abs(tcalc)])
ncolr=length(mid[mid>=  abs(tcalc)])
col=c(rep("Green",ncoll),rep("Gray",length(mid)-ncoll-ncolr),rep("Green",ncolr))
}
hist(tstat,col=col,freq=FALSE)
#segments(ci[1],0,ci[2],0,lwd=2)

return(list(pvalue=pvalue))
#return(list(pvalue=pvalue,tcalc=tcalc,n=n,x=x,test=test,ci=ci))
}

set.seed(30)
x=rnorm(15,mean=10,sd=7)   
set.seed(40)
y=rnorm(20,mean=12,sd=4)
```


Here we redo the test in Task 3 using bootstrap. 

For the case $\mu_y - \mu_x = 0$

```{r}

boot2pval(x1 = y, x2 = x, mudiff = 0)

```

For the case $\mu_y - \mu_x = 2$
```{r}

boot2pval(x1 = y, x2 = x, mudiff = 2)

```

# Task 6
```{r}

set.seed(30)
x=rnorm(15,mean=10,sd=4)   
set.seed(40)
y=rnorm(20,mean=12,sd=4)

```

Here we redo the test in Task 4 using bootstrap. 

For the case $\mu_y - \mu_x = 0$

```{r}

boot2pval(x1 = y, x2 = x, mudiff = 0)

```

For the case $\mu_y - \mu_x = 2$
```{r}

boot2pval(x1 = y, x2 = x, mudiff = 2)

```

# Task 7

Here we explain the line-by-line meaning of the `t.test()` output. 

```
> t.test(x1,mu=23) # A
	
      One Sample t-test # B

data:  x1
t = 2.3563, df = 29, p-value = 0.02543 # C
alternative hypothesis: true mean is not equal to 23 #D
95 percent confidence interval: #E
23.30198 27.27320 #F
sample estimates:
mean of x 
25.28759 #G
```

#A : performs one-sample `t.test()` on samples contained by vector x1, with null value being 23. 

#B : Header describing the test being performed. 

#C: this line contains t-statistics calculated, degree of freedom, and the p-value. The p-value is one of the indicator whether or not we should reject the Null hypothesis. 

#D: Literally provide the alternate hypothesis. 

#E: Explicitly describing the confidence interval.

#F: Giving the lower (left) and the upper (right) bounds of the interval, whose level described in #E.

#G: mean of vector x1. 

# Task 8
```{r}

library(math4753)

set.seed(30)
x=rnorm(15,mean=10,sd=4)   
set.seed(40)
y=rnorm(20,mean=12,sd=4)

myboot2pval(x1 = x, x2 = y, mudiff = 3)

```

